---
title: Random Forest for Trees
author: Willian Vieira
date: "`r paste('Last updated on', format(Sys.time(), '%d %B, %Y'))`"
---

```{r load R packages, echo=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(DT))
```

```{r getting variables, echo=FALSE}

  # species_id
  sp_ids = as.character(read.table('data/sp_ids.txt')[, 1])

  # other variables from the simulation file
  rFile <- readLines('R/03_runSimulations.R')
```

# Introduction

Here I use the random forest method to extract the power of different variables to explain **growth**,  **mortality** and **recruitment** of tree species.
I use the forest inventory data base for the eastern North American forest.

For each tree species in the data base (total of `r length(sp_ids)`), we will run a random forest for growth, mortality and recruitment with different parameters and explanatory variables.
Then we evaluate the simulation based on the R$^2$ for the growth and recruitment, and the out-of-bag estimate (1 - OOB) for mortality.
For mortality, in which alive events are much more frequent than dead events, we avoid overestimating OOB by balancing the sampling weights to have the same number of observations from each class as suggested in Janitza & Hornung ([2018](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201904)).
We further check which variables have a better explanatory power over the response variable.

# Simulations

For each tree species, we ran a random forest varying (i) the explanatory variables, and (ii) the number of variables to possibly split at in each node (`mtry`).
The set of variables for **growth** and **mortaltiy** are the following:

```{r table of variables, echo=FALSE}
# get variables
vars <- read.table('data/variables.txt')[, 1]
print(as.character(vars))
```

And for **recruitment**, in which is quantified at the $plot$ and $species$ level, the set of variables are:

```{r table of variables fec, echo=FALSE}
varsFec <- read.table('data/variables_fec.txt')[, 1]
print(as.character(varsFec))
```

# Summary

```{r prepare data, echo=FALSE}
# data frame to save explanatory power
dfPw <- expand.grid(c('fec', 'mort', 'growth'), sp_ids)
names(dfPw) <- c('vital', 'sp')
dfPw$pw <- rep(NA, nrow(dfPw))

# add species information
sp_info <- read.table('data/sp_info.txt')
dfPw <- merge(dfPw, sp_info[, c(1, 2, 5)], by.x = 'sp', by.y = 'species_id')

# reorganize df
dfPw <- dfPw[, c(2, 1, 4, 5, 3)]

# data frame to get importance
varsTotal <- unique(c(as.character(vars), gsub("_mLag.*", "", as.character(varsFec))))
dfImportance <- as.data.frame(matrix(rep(NA, length(varsTotal) * nrow(dfPw)), ncol = length(varsTotal)))
names(dfImportance) <- varsTotal

# load each simulation and import all information
for(vital in c('fec', 'mort', 'growth'))
{
  for(sp in sp_ids)
  {

    # get dfPw row
    Row <- which(dfPw$vital == vital & dfPw$sp == sp)

    # load simulation
    sim <- readRDS(paste0('output/', vital, '_', sp, '.RDS'))

    # get explanatory power
    if(sim$treetype == 'Regression') {
      dfPw[Row, 'pw'] = sim$r.squared
    }else if(sim$treetype == 'Classification') {
      dfPw[Row, 'pw'] = 1 - sim$prediction.error
    }

    # get importance
    impRF <- ranger::importance(sim)
    # drop `mLag` in importance name
    names(impRF) <- gsub("_mLag.*", "", names(impRF))
    
    if(all(names(impRF) %in% names(dfImportance)))
    {
      dfImportance[Row, names(impRF)] <- impRF
    }else{
      missingVars <- names(impRF)[!(names(impRF) %in% names(dfImportance))]
      stop(paste0('These variables are missing on the dfImportance: ', paste0(missingVars, collapse = ' ')))
    }
  }
}


# tranform to long format
dfLong = gather(cbind(dfPw, dfImportance), variable, importance, growth:relativeBA_sp, factor_key = TRUE)


## Get sample size with median pw
pwSp <- dfPw %>%
        group_by(vital, sp) %>%
        summarise(median = median(pw))

# add training size
pwSp <- merge(pwSp, read.table('data/trainingSize_spIds.txt'), by.x = c('vital', 'sp'), by.y = c('vital', 'sp'))

# add species info
pwSp <- merge(pwSp, sp_info[, 1:2], by.x = 'sp', by.y = 'species_id')
```

## Variable importance

Assuming the set of variables `var1` was the best to explain recruitment and mortality, let's see the importance of the variables present in the set `var1`:

```{r variable set importance growth, echo=FALSE}
p = ggplot(data = droplevels(dfLong)) +
    aes(reorder(variable, importance, FUN = median), log(importance)) +
    geom_boxplot() +
    coord_flip() +
    facet_grid(~vital, scales = "free_x") +
    theme_classic() +
    xlab("Variables in set 1") +
    ylab("Importance (log)")

suppressWarnings(print(p))
```

## Individual species response

Which species perform the better?

```{r species_id, echo=FALSE}
p = ggplot(data = dfPw) +
    aes(reorder(latin, pw, FUN = median), pw) +
    geom_boxplot() +
    coord_flip() +
    facet_grid(~vital,
              labeller = labeller(vital = setNames(c('Growth (Rsquared)',
                                  'mort (1 - OOB)',
                                  'fec (Rsquared)'),
                                  c('growth', 'mort', 'fec')))) +
    theme_classic() +
    xlab("Species") +
    ylab("Explanatory power of variables")

print(p)
```

What was the best predictor for each species?

```{r best predictors by species, echo=FALSE}

## Get sample size with median pw
bestPredicSp <- dfLong %>%
                group_by(vital, latin) %>%
                summarise(bestPredic = variable[which.max(importance)])

bestPredicWide <- spread(bestPredicSp, vital, bestPredic)

DT::datatable(bestPredicWide)
```

And when species are grouped by tolerance to shade? _**H**igh, **M**edium, and **L**ow tolerance to shade_.

```{r shade tolerance, echo=FALSE, fig.height=10}
p = ggplot(data = dfLong) +
    aes(reorder(tolLevel, importance, FUN = median), importance) +
    geom_boxplot() +
    coord_flip() +
    facet_grid(variable~vital, scales = "free_x") +
    scale_y_log10() +
    theme_classic() +
    xlab("Tolerance level") +
    ylab("Importance")

suppressWarnings(print(p))
```

```{r shade tolerance table, echo=FALSE}
bestPredicSp <- dfLong %>%
                group_by(vital, tolLevel) %>%
                summarise(bestPredic = variable[which.max(importance)])

bestPredicWide <- spread(bestPredicSp, vital, bestPredic)

DT::datatable(bestPredicWide)
```


Is there a correlation between explanatory power and sample size?

```{r species_id vs n, echo=FALSE}
p = ggplot(data = pwSp) +
    aes(trainingSize, median) +
    geom_point() +
    geom_smooth(method='lm', formula= y ~ x + I(x^2)) +
    facet_grid(~vital, scales = "free_x",
              labeller = labeller(vital = setNames(c('growth (Rsquared)',
                                  'mort (1 - OOB)',
                                  'fec (Rscquared)'),
                                  c('growth', 'mort', 'fec')))) +
    theme_classic() +
    xlab("Sample size") +
    ylab("Explanatory power of variables")

print(p)
```

```{r table with performance and n, echo=FALSE}
names(pwSp)[3] <- 'Explain'
pwSp$Explain <- round(pwSp$Explain, 3)

perform <- pivot_wider(data = pwSp,
                 id_cols = latin,
                 names_from = vital,
                 values_from = c("Explain", "trainingSize"))

DT::datatable(perform)
```
